{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cLWHluV2tfN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9c9c0a-eebc-4b2b-e79d-944fe2173d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 15s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.reshape((50000, 32, 32,3))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((10000, 32, 32,3))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "Y_train = to_categorical(Y_train)\n",
        "Y_test = to_categorical(Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfamnaVwuGaH",
        "outputId": "50769f49-755f-4cb9-9ef9-7432f7d1962e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 2, 2, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,202\n",
            "Trainable params: 160,202\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijWk4ejY162y",
        "outputId": "9e46926d-e149-4371-afd7-3f8757d5ce6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 2.0311 - accuracy: 0.2746\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.7499 - accuracy: 0.3701\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.6333 - accuracy: 0.4111\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.5516 - accuracy: 0.4421\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4925 - accuracy: 0.4621\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4440 - accuracy: 0.4826\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.4040 - accuracy: 0.4989\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3708 - accuracy: 0.5130\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3398 - accuracy: 0.5244\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.3144 - accuracy: 0.5333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcd6c294e80>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(optimizers.RMSprop(lr=1e-4),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, epochs=10, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQalokln2F66"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "I decided to use the cifar10 dataset. After difficulty obtaining the data from the link provided, I instead looked to the internet to find a different source for the data. I then realized that the data is a standard dataset on keras, similar to the MNIST data. Although the images and classifications are different, I thought it could still work since I was able to import it. I split the data, and then preprocessed it the same way I did with the MNIST data. Shaping it correctly and changing the pixel values from 0-255 to 0-1. Then I changed the labels from their normal classifications to hot encoded labels. Now we have 10 different classifications that are all 0 or 1. Then I built a very similar model to what we used for MNIST. I tried adding dropout layers after the pooling layers, but it didnt increase performance. After compiling and fitting the model the same way as we did with the MNIST data, the accuracy was OK. A bit over 0.5 accuracy for a dataset with 10 classifications is, all things considered, not that bad."
      ],
      "metadata": {
        "id": "tPG2Z1HkkcdU"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}